{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Term Behavior of Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov chains could be used to model countless phenomena that happen in our world, but we would have to assume and accept that what we are trying to model depends only on the last step, not on all previous steps (or the whole history). \n",
    "\n",
    "For example, Sahin and Sen (2001) modeled hourly wind speeds in a NW part of Turkey as a Markov chain ${(X_n)}_{n\\in \\mathbb{N}}$, with 7 states representing different wind speed levels.\n",
    "\n",
    "Let us consider the states to be $S=\\{0,1,2,3,4,5,6 \\}$, with $0$ representing the lowest wind speed level. The transition matrix is given by...\n",
    "\n",
    "\\begin{gather*}\n",
    "P=\\begin{array}{cccccccc}\n",
    "& 0 & 1 & 2 & 3 & 4 & 5 & 6 \\\\\n",
    "0 & 0.756 & 0.113 & 0.129 & 0.002 & 0 & 0 & 0\\\\\n",
    "1 & 0.174 & 0.821 & 0.004 & 0.001 & 0 & 0 & 0\\\\\n",
    "2 & 0.141 & 0.001 & 0.776 & 0.082 & 0 & 0 & 0\\\\\n",
    "3 & 0.003 & 0 & 0.192 & 0.753 & 0.052 & 0 & 0\\\\\n",
    "4 & 0 & 0 & 0.002 & 0.227 & 0.735 & 0.036 & 0\\\\\n",
    "5 & 0 & 0 & 0 & 0.007 & 0.367 & 0.604 & 0.022\\\\\n",
    "6 & 0 & 0 & 0 & 0 & 0.053 & 0.158 & 0.789\\\\\n",
    "\\end{array}\n",
    "\\end{gather*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions and Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Definition:</b> An irreducible finite state space Markov chain with transition matrix $P$ has a unique stationary distribution $\\pi$ which satisfies $\\pi^T P = \\pi^T$.\n",
    "\n",
    "<b>Theorem:</b> If a Markov chain is irreducible, aperiodic and has a unique stationary distribution $\\pi$, then we have that\n",
    "\n",
    "$$ \\lim_{n\\rightarrow\\infty} {P}^{ n}_{ij} = \\pi_j \\quad \\text{ for all } i,j \\in \\mathcal{S}.$$\n",
    "\n",
    "We will check that these theorems hold by computing $P^{250}$ and using the definition of a stationary distribution to compute $\\pi$ that fullfils $\\pi^T P = \\pi^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from numpy import linalg \n",
    "import csv\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = '/Users/hunt_wern/OneDrive/GitHub/Statistical-Analysis/Data/Wind_Speeds.csv'\n",
    "P = []\n",
    "with open(csvFile,'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        P.append([float(prob) for prob in row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll check that the matrix was read correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.756, 0.113, 0.129, 0.002, 0.   , 0.   , 0.   ],\n",
       "       [0.174, 0.821, 0.004, 0.001, 0.   , 0.   , 0.   ],\n",
       "       [0.141, 0.001, 0.776, 0.082, 0.   , 0.   , 0.   ],\n",
       "       [0.003, 0.   , 0.192, 0.753, 0.052, 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.002, 0.227, 0.735, 0.036, 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.007, 0.367, 0.604, 0.022],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.053, 0.158, 0.789]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P=np.array(P)\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing $P^{250}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check that the theorem holds by computing $P^{250}$ and listing its rows (remember that according to the theorem, for large $n$, all rows should be almost equal to the limiting distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.24586174e-01 2.06604292e-01 3.03930586e-01 1.31889029e-01\n",
      "  2.98620155e-02 2.83256580e-03 2.95338614e-04]\n",
      " [3.24586174e-01 2.06604292e-01 3.03930586e-01 1.31889029e-01\n",
      "  2.98620155e-02 2.83256580e-03 2.95338614e-04]\n",
      " [3.24586174e-01 2.06604292e-01 3.03930586e-01 1.31889029e-01\n",
      "  2.98620155e-02 2.83256580e-03 2.95338614e-04]\n",
      " [3.24586174e-01 2.06604292e-01 3.03930586e-01 1.31889029e-01\n",
      "  2.98620155e-02 2.83256580e-03 2.95338614e-04]\n",
      " [3.24586174e-01 2.06604292e-01 3.03930586e-01 1.31889029e-01\n",
      "  2.98620155e-02 2.83256580e-03 2.95338614e-04]\n",
      " [3.24586174e-01 2.06604292e-01 3.03930586e-01 1.31889029e-01\n",
      "  2.98620155e-02 2.83256580e-03 2.95338614e-04]\n",
      " [3.24586174e-01 2.06604292e-01 3.03930586e-01 1.31889029e-01\n",
      "  2.98620155e-02 2.83256580e-03 2.95338614e-04]]\n"
     ]
    }
   ],
   "source": [
    "p250 = np.linalg.matrix_power(P,250)\n",
    "print(p250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing $\\pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll compute the stationary distribution $\\pi$ by using the definition $\\pi^T P = \\pi^T$.\n",
    "    \n",
    "Note that in linear algebra, all vectors are column vectors, and since in the definition we have a row vector $\\pi^T$, if we take the transpose and use the fact that ${(AB)}^T=B^TA^T$, we obtain $P^T\\pi = \\pi$. \n",
    "\n",
    "For a stationary distribution, $\\lambda=1$ is an eigenvalue to the matrix $P^T$ with eigenvector $v=\\pi$. Therefore, in order to quickly find the stationary distribution, we can look at the positive eigenvectors that correspond to the eigenvalue $1$ for the matrix $P^T$. Then, we just normalize it so that the entries add up to $1$ (since it is a distribution vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.24586174e-01 2.06604292e-01 3.03930586e-01 1.31889029e-01\n",
      " 2.98620155e-02 2.83256580e-03 2.95338614e-04]\n"
     ]
    }
   ],
   "source": [
    "pt = np.matrix.transpose(P)\n",
    "eigenvector = np.linalg.eig(pt)[1][:,0]\n",
    "stationaryDist = eigenvector/sum(eigenvector)\n",
    "print(stationaryDist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Return Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Theorem:</b> For any finite irreducible Markov chain we have that the stationary distribution $\\pi$ satisfies\n",
    "$$ \\pi_j=\\frac{1}{\\mathbb{E}[T_j\\,| \\,X_0=j]} \\quad \\text{ for all } j \\in \\mathcal{S} $$\n",
    "\n",
    "where $T_j = \\min\\{n>0:X_n=j \\}$ denotes the first visiting time of state $j$ after having started in $j$ at time 0.\n",
    "\n",
    "Hence, in order to find the expected return time to state $j$, we just have to compute $1/\\pi_j$.\n",
    "\n",
    "We will check that this theorem holds for state $0$ by simulating $N=10^5$ Markov Chains, starting at $0$, with transition matrix $P$. Each Markov chain will be simulated until state $0$ is reached again. Our approximation of $\\mathbb{E}[T_0 \\,| \\, X_0=0]$ will be the average of all of the return times. Because of the above theorem, the estimate should be close to $1/\\pi_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of zero entry = 0.32634945499641016\n",
      "Actual zero entry = 0.324586173886771\n"
     ]
    }
   ],
   "source": [
    "N = 10**5\n",
    "revisitTimes = []\n",
    "for i in range(N):\n",
    "    currState = 0\n",
    "    i = 0\n",
    "    done = False\n",
    "    while done == False:\n",
    "        newState = np.random.choice(a=range(7),p=P[currState])\n",
    "        i += 1\n",
    "        if newState == 0:\n",
    "            done = True\n",
    "        currState = newState\n",
    "    revisitTimes.append(i)\n",
    "expectedRevisit = sum(revisitTimes)/N\n",
    "\n",
    "sdZeroEstimate = 1/expectedRevisit\n",
    "sdZeroActual = stationaryDist[0]\n",
    "print('Estimate of zero entry = ' + str(sdZeroEstimate))\n",
    "print('Actual zero entry = ' + str(sdZeroActual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
